{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "op4eZdzcdgiR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) #mounting my google drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "FacBP7zBd9Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/KAGGLE_API_CREDENTIALS/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "vLWdj8WBelbr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "WDAwQs62fL1y"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "import copy"
      ],
      "metadata": {
        "id": "ekmOSMSwf9_2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' #setting up device agnostic code"
      ],
      "metadata": {
        "id": "Gsh0Kd6chAwk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d ananthu017/emotion-detection-fer #downloading dataset in zip form"
      ],
      "metadata": {
        "id": "390quVDchRnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/emotion-detection-fer.zip #unzipping dataset"
      ],
      "metadata": {
        "id": "9tGbv-1Uhhu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([ #transfromations i want applied on train images\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Grayscale(num_output_channels=1),  # convert to grayscale\n",
        "    transforms.Normalize(mean=[0.485], std=[0.229])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([ #transfromations i want applied on test images\n",
        "    transforms.Grayscale(num_output_channels=1),  # convert to grayscale\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "ZgwC8q3hhsvA"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder('/content/train', transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder('/content/test', transform=test_transform)"
      ],
      "metadata": {
        "id": "ZlMOnT4El5xz"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#it's an imbalanced dataset, so I'm taking into account the number of each classes\n",
        "\n",
        "angry_label = train_dataset.class_to_idx['angry']  # get the label of 'angry'\n",
        "num_angry_images = sum(label == angry_label for _, label in train_dataset)  # count how many images have this label\n",
        "\n",
        "disgusted_label = train_dataset.class_to_idx['disgusted']  # get the label of 'disgusted'\n",
        "num_disgusted_images = sum(label == disgusted_label for _, label in train_dataset)\n",
        "\n",
        "fearful_label = train_dataset.class_to_idx['fearful']  # get the label of 'fearful'\n",
        "num_fearful_images = sum(label == fearful_label for _, label in train_dataset)\n",
        "\n",
        "happy_label = train_dataset.class_to_idx['happy']  # get the label of 'happy'\n",
        "num_happy_images = sum(label == happy_label for _, label in train_dataset)\n",
        "\n",
        "neutral_label = train_dataset.class_to_idx['neutral']  # get the label of 'neutral'\n",
        "num_neutral_images = sum(label == neutral_label for _, label in train_dataset)\n",
        "\n",
        "sad_label = train_dataset.class_to_idx['sad']  # get the label of 'sad'\n",
        "num_sad_images = sum(label == sad_label for _, label in train_dataset)\n",
        "\n",
        "surprised_label = train_dataset.class_to_idx['surprised']  # get the label of 'surprised'\n",
        "num_surprised_images = sum(label == surprised_label for _, label in train_dataset)\n",
        "\n"
      ],
      "metadata": {
        "id": "vX9L5m_zs5dj"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_images = len(train_dataset)\n",
        "\n",
        "weights = [\n",
        "    total_images / num_angry_images,\n",
        "    total_images / num_disgusted_images,\n",
        "    total_images / num_fearful_images,\n",
        "    total_images / num_happy_images,\n",
        "    total_images / num_neutral_images,\n",
        "    total_images / num_sad_images,\n",
        "    total_images / num_surprised_images,\n",
        "]\n",
        "\n",
        "weights = [weight / sum(weights) for weight in weights] #normalizing the weights so they add up to 1\n"
      ],
      "metadata": {
        "id": "k_TYfIdpuKza"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUmEy5XOaEwS",
        "outputId": "dcfcdb89-9b12-453f-bbcc-c531ff67a6ff"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06857175062953616, 0.6283122563417362, 0.06686457011593774, 0.03796869629452487, 0.055175054131922856, 0.05671721403002007, 0.08639045845632197]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32 #splitting my datasets into random mini batches\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset,batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "f2q7MgGkmxBN"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Emotion_Detection_Model_V1(nn.Module):\n",
        "  def __init__(self, input_shape , output_shape):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape, out_channels=96, stride=1, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = 96, out_channels=108, stride=1, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=108, out_channels=120, stride=1, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = 120, out_channels=140, stride=1, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    self.conv_block_3 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=140, out_channels=160, stride=1, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = 160, out_channels=200, stride=1, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    self.conv_block_4 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=200, out_channels=260, stride=1, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = 260, out_channels=300, stride=1, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    self.classifier_layer = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=2700,out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self,X):\n",
        "    X = self.conv_block_1(X)\n",
        "    X = self.conv_block_2(X)\n",
        "    X = self.conv_block_3(X)\n",
        "    X = self.conv_block_4(X)\n",
        "    X = self.classifier_layer(X)\n",
        "\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "Yn7xLxBEnSla"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = Emotion_Detection_Model_V1(input_shape=1,output_shape=len(train_dataset.classes)).to(device)"
      ],
      "metadata": {
        "id": "pXTozf3n48JP"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.Tensor(weights).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=weights)\n"
      ],
      "metadata": {
        "id": "YbXjYkei5aoS"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_stage(model=None,loss_fn=None, learning_rate=None,train_loader=None):\n",
        "\n",
        "\n",
        "  optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
        "  model.train()\n",
        "\n",
        "  for X_train,y_train in train_loader:\n",
        "    X_train,y_train = X_train.to(device), y_train.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(X_train)\n",
        "    train_loss = loss_fn(y_pred,y_train)\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "id": "nVKdNkLX6_N4"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_stage(model=None,test_loader=None):\n",
        "  with torch.inference_mode():\n",
        "    model.eval()\n",
        "    y_trues = []\n",
        "    y_preds = []\n",
        "    for X_test,y_test in test_loader:\n",
        "      X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "      y_pred = model(X_test)\n",
        "\n",
        "      y_trues.extend(list(y_test.cpu().numpy()))\n",
        "      y_preds.extend(list(y_pred.argmax(dim=1).cpu().numpy()))\n",
        "\n",
        "    return (y_trues,y_preds)"
      ],
      "metadata": {
        "id": "Rec-8A5hMLuo"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "best_accuracy = 0.0\n",
        "best_report = None\n",
        "best_model_weights = model_0.state_dict()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_stage(model=model_0,loss_fn=loss_fn,learning_rate=0.01,train_loader=train_loader)\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    y_trues, y_preds = test_stage(model=model_0, test_loader=test_loader)\n",
        "    report = classification_report(\n",
        "        y_true=y_trues,\n",
        "        y_pred=y_preds,\n",
        "        output_dict=True,\n",
        "        target_names=test_dataset.classes,\n",
        "        zero_division='warn'\n",
        "    )\n",
        "\n",
        "    if report['accuracy'] > best_accuracy:\n",
        "      best_report = report\n",
        "      best_model_weights = copy.deepcopy(model_0.state_dict())\n",
        "\n",
        "  print(epoch)\n",
        "\n"
      ],
      "metadata": {
        "id": "EKVKT_dc9Bc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_report)"
      ],
      "metadata": {
        "id": "3cI3Uy0yg5FR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a188898-4d8e-404e-f3bf-28874741b1eb"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'angry': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 958}, 'disgusted': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 111}, 'fearful': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1024}, 'happy': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1774}, 'neutral': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1233}, 'sad': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1247}, 'surprised': {'precision': 0.11577040958484257, 'recall': 1.0, 'f1-score': 0.20751654388812585, 'support': 831}, 'accuracy': 0.11577040958484257, 'macro avg': {'precision': 0.016538629940691794, 'recall': 0.14285714285714285, 'f1-score': 0.02964522055544655, 'support': 7178}, 'weighted avg': {'precision': 0.01340278773544221, 'recall': 0.11577040958484257, 'f1-score': 0.02402427528155929, 'support': 7178}}\n"
          ]
        }
      ]
    }
  ]
}